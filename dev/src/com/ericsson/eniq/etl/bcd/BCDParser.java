package com.ericsson.eniq.etl.bcd;

import java.io.File;
import java.io.IOException;
import java.io.PrintWriter;
import java.nio.file.Files;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.HashMap;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.StringTokenizer;
import org.xml.sax.Attributes;
import org.xml.sax.SAXException;
import org.xml.sax.helpers.DefaultHandler;

import com.distocraft.dc5000.etl.parser.Main;
import com.distocraft.dc5000.etl.parser.MeasurementFile;
import com.distocraft.dc5000.etl.parser.Parser;
import com.distocraft.dc5000.etl.parser.SourceFile;
import com.distocraft.dc5000.etl.parser.xmltransformer.ConfigLookup;
import com.distocraft.dc5000.repository.cache.DFormat;
import com.distocraft.dc5000.repository.cache.DItem;
import com.distocraft.dc5000.repository.cache.DataFormatCache;
//import com.sybase.jdbc3.tds.DataFormat;

import java.util.Map.Entry;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.regex.PatternSyntaxException;
import java.util.stream.Collectors;
import java.util.stream.Stream;

import javax.xml.parsers.ParserConfigurationException;
import javax.xml.parsers.SAXParser;
import javax.xml.parsers.SAXParserFactory;

/**
 * Parses a topology (CM data) xml generated by OSS-RC, of format bulkCmConfigDataFile. The <br>
 * <table border="1" width="100%" cellpadding="3" cellspacing="0">
 * <tr bgcolor="#CCCCFF" class="TableHeasingColor">
 * <td colspan="3"><font size="+2"><b>Parameter Summary</b></font></td>
 * </tr>
 * <tr>
 * <td><b>Key Name</b ></td>
 * <td><b>Description</b></td>
 * <td><b>Default</b></td>
 * </tr>
 * <tr>
 * <td>BCDParser.removeRootMoR</td>
 * <td>Determinates whether the _R should be removed from FDN and from Managed
 * Object references.</td>
 * <td>true</td>
 * </tr>
 * <tr>
 * <td>BCDParser.removeVsData</td>
 * <td>Determinates whether the vsData should be removed from FDN and from
 * Managed Object references.</td>
 * <td>true</td>
 * </tr>
 * <tr>
 * <td>BCDParser.sequenceSeparator</td>
 * <td>Defines the value that is used to separate sequence lists when they're
 * are loaded to non-vector table.</td>
 * <td>;</td>
 * </tr>
 * </table>
 * <br>
 * <br>
 * 
 * <table border="1" width="100%" cellpadding="3" cellspacing="0">
 * <tr bgcolor="#CCCCFF" class="TableHeasingColor">
 * <td colspan="4"><font size="+2"><b>Added DataColumns</b></font></td>
 * </tr>
 * <tr>
 * <td><b>Column name</b></td>
 * <td><b>Description</b></td>
 * <td><b>Depends on Parameter(s)</b></td>
 * <td><b>Default</b></td>
 * </tr>
 * <tr>
 * <td>AOM</td>
 * <td>Contains the AOM Number. Taken with Interface Transformation Pattern from filename.</td>
 * <td>
 * <div> BCDParser.aomIdentifier </div> <div> BCDParser.aomPattern </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>CU</td>
 * <td>Contains the OSS CU Number. Taken with Interface Transformation Pattern from filename.</td>
 * <td>
 * <div> BCDParser.cuIdentifier </div> <div> BCDParser.cuPattern </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DATETIME_ID</td>
 * <td>Contains the Datetime ID. Taken from filename.</td>
 * <td>BCDParser.dateTimeIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DIRNAME</td>
 * <td>Contains the full path to the inputfile.</td>
 * <td>BCDParser.dirnameIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_RELEASE</td>
 * <td>Contains the OSS Release. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>
 * <div> BCDParser.releaseIdentifier </div> <div> BCDParser.releasePattern
 * </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_SOURCE</td>
 * <td>Contains the DC Source value. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>BCDParser.sourceIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_TIMEZONE</td>
 * <td>Contains the Timezone value. Taken from filename.</td>
 * <td>BCDParser.timezoneIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DCVECTOR_INDEX</td>
 * <td>Contains the range index of sequence (e.g. VECTOR) measurements.</td>
 * <td>BCDParser.sequenceIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * 
 * <tr>
 * <td>ELEMENT</td>
 * <td>Contains the name of the Element. Only applicable for Measurement's that
 * have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>ELEMENTPARENT</td>
 * <td>Contains the parent of the Element. Only applicable for Measurement's
 * that have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>ELEMENTTYPE</td>
 * <td>Contains the type of the Element. Only applicable for Measurement's that
 * have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * 
 * 
 * <tr>
 * <td>FDN</td>
 * <td>Contains the Fully Distinguished Name of the Managed Object.</td>
 * <td>BCDParser.fdnIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>FILENAME</td>
 * <td>Contains the filename of the inputfile.</td>
 * <td>BCDParser.filenameIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>JVM_TIMEZONE</td>
 * <td>Contains the JVM timezone (example. +0200)</td>
 * <td>BCDParser.jvmTimezoneIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>MOID</td>
 * <td>Contains the Managed Object Identifier part from FDN.</td>
 * <td>BCDParser.moidIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>OSS_ID</td>
 * <td>Contains the OSS Identifier. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>
 * <div> BCDParser.ossIdPattern </div> <div> BCDParser.ossIdIdentifier </div></td>
 * <td>&nbsp;</td>
 * </tr>
 *<tr>
 * <td>PERIOD_DURATION</td>
 * <td>Contains the Period Duration. Fixed value.</td>
 * <td>BCDParser.periodDurationIdentifier</td>
 * <td>1440</td>
 * </tr>
 * <tr>
 * <td>SN</td>
 * <td>Contains the Sender Name part from FDN.</td>
 * <td>BCDParser.snIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * <tr>
 * <td>TIMELEVEL</td>
 * <td>Contains the Timelevel. Fixed value.</td>
 * <td>BCDParser.timelevelIdentifier</td>
 * <td>24H</td>
 * </tr>
 * 
 * </table>
 * <h1>Example</h1> <div> 1. Inputfiles are located in
 * /eniq/data/pmdata/eniq_oss_1/foo/1<br/>
 * 2. BCDParser.ossIdentifier is set to: FooKey<br/>
 * 3. BCDParser.ossPattern is set to: .+//(.+)//.+//.+ </div> <br/>
 * <br/>
 * <div>This would result the parser to produce a key called FooKey with value
 * of the eniq_oss_1 </div> <br/>
 * <br/>
 * 
 * @author Jouni Makinen (lmfjou)
 * 
 */
public class BCDParser extends DefaultHandler implements Parser {
	/*
	 * Nodetypes
	 */
    //  This is modified for the JIRA EQEV-40732
	final String OSSRC = "OSS";
	final String RNC = "RNC";
	final String TDRNC = "TDRNC";
	final String TDRBS = "TDRBS";
	final String RBS = "RBS";
	final String ENM="ENM";
	
	
	private static final int maxLength = 256;
	String elementType = OSSRC;
	String parentNode = null;
	String elementNode = null;
	int FdnCount = 0;
	//modified for JIRA: EQEV-53994 (HX21519)
	final String ES_MANAGEDELEMENT_TYPE = "es:managedElementType";
	final String XN_MANAGEDELEMENT_TYPE = "xn:managedElementType";
	/*
	 * Interface parameters
	 */
	boolean removeRootMoR;
	boolean removeVsData;
	String fdnIdentifier;
	String snIdentifier;
	String moidIdentifier;
	String structIdentifier;
	String sequenceSeparator;
	String sequenceIdentifier;
	String aomIdentifier;
	String cuIdentifier;
	String releaseIdentifier;
	String dateTimeIdentifier;
	String timezoneIdentifier;
	String timelevelIdentifier;
	String periodDurationIdentifier;
	String ossIdIdentifier;
	String sourceIdentifier;
	String filenameIdentifier;
	String jvmTimezoneIdentifier;
	String dirnameIdentifier;
	/*
	 * Interface filelookup parameters
	 */
	String aomPattern;
	String cuPattern;
	String releasePattern;
	String hostnamePattern;  //Never used
	String datetimeIdPattern;
	String ossIdPattern;
	String timeZonePattern;
	String inDir;
	String aom;
	String cu;
	String release;
	String hostname;
	String datetimeId;
	String timeZone;
	String ossId;
	String timelevel;
	String periodDuration;
	ArrayList<String> elementTypesSup = new ArrayList<String>(); //EDEAMAI - Comma separated list os supported node types.
	String elementTypesFDN; //EDEAMAI - Comma separated list of nodes with FDN pattern provided.
	/*
	 * MO Parameters
	 */
	Fdn fdn = null;
	String moId = null;
	String moClass = null;
	String parentMoClass = null;
	String parentMoId = null;
	String vsDataClass = "";
	int fdnDepth = 0;
	int attributeDepth = 0;
	/*
	 * Handling parameters
	 */
	boolean collect = false;
	boolean isStruct = false;
	private boolean isManagedElement = false;
	/*
	 * XML Tags
	 */
	String elementParent = null;
	String elementStart = null;
	String elementEnd = null;
	String elementStruct = null;
	StringBuilder characters = null;
	/*
	 * DataMap which contains attributes
	 */
	HashMap<String, String> dataMap = null;
	HashMap<String, String> docDataMap = null;
	LinkedHashMap<String, HashMap<String, String>> vectorMap;
	LinkedHashMap<String,HashMap<String,String>> subVectorMap;
	HashMap<String, Integer> vectorCountersIndexMap;

	/*
	 * Document variables
	 */
	long start;
	long stop;
	
	/*
	 * Parser parameters
	 */
	private static final String JVM_TIMEZONE = new SimpleDateFormat("Z").format(new Date());
	HashMap<String, MeasurementFile> openFiles;
	HashMap<String, List<String>> vectorListSet;
	private Logger logger;
	private Main mainParser;
	private String techPack;
	private String setType;
	private String setName;
	private int status = 0;
	private String workerName;
	private SourceFile sourceFile;

	// XTOUOOS - Variables
	String previousElement = null;
	List<String> vecNameList = null;
	String intfName = null;
	
	public static final String COMMA_SEPARATOR = ",";
	public static final String OSS_MAPPING_HEADER = "OSSALIAS" + COMMA_SEPARATOR + "OSSID";
	public static final String TEXT_FORMAT = ".txt";
	ArrayList<MeasurementFile> measurementData=new ArrayList<MeasurementFile>();
	ArrayList<HashMap<String,String>> dataMapList=new ArrayList<HashMap<String,String>>();
		
	/**
     * Parameters for throughput measurement.
     */
    private long parseStartTime;
    private long totalParseTime;
    private long fileSize;
    private int fileCount;
	/*
     * Handle atribute depth Level==3, TECS-1687
     */
    String elementGrandParent = null;								 
        	
	/**
	 * Initilizes the parameters needed for parsing
	 * 
	 */
	public void startDocument() throws SAXException {
		start = Calendar.getInstance().getTimeInMillis();
		logger.log(Level.FINEST, "Parser entering startDocument()....");
	}

	/**
	 * Lookups variables from filename
	 * 
	 * @param name
	 *            of the input file
	 * @param pattern
	 *            the pattern to lookup from the filename
	 * @return result returns the group(1) of result, or null
	 */
	private String transformFileVariables(String transformation, String filename, String pattern) {
		String result = null;
		try {
			Pattern p = Pattern.compile(pattern);
			Matcher m = p.matcher(filename);
			if (m.matches()) {
				result = m.group(1);
			}
		} catch (PatternSyntaxException e) {
			logger.log(Level.SEVERE, "Error performing transformFileVariables for BCDParser." + transformation, e);
		}
		return result;
	}

	/**
	 * Writes the parsed keys to the MeasurementFile
	 * 
	 * @param String
	 *            mo Name of the ManagedObject that is being written
	 * @param String
	 *            id The identifier of the ManagedObject that is being written
	 */
		private Map<String, String> getMoData(String mo, String id) {
		HashMap<String, String> moData = new HashMap<>();
		moData.put(fdnIdentifier, fdn.getFdn());
		moData.put(snIdentifier, fdn.getSn());
		moData.put(moidIdentifier, fdn.getMoid());
		moData.put(mo , id);
		/*
		 * Add Element Data types to map
		 */
		final HashMap<String, String> elementDataMap = getElementData();
		if (!elementDataMap.isEmpty()) {
			moData.putAll(elementDataMap);
		}
		return moData;
	}
		private void writeData(String mo, String id,boolean isWrite) {
			try {
				/*
				 * Get the MeasurementFiles for ManagedObject Class
				 */
				MeasurementFile dataFile = getMFile(mo);
				MeasurementFile vectorFile = getMFile(mo + "_V");
				
				logger.log(Level.FINE, "Trying to write MO " + mo + "=" + id + " to MeasurementFile.");
				/*
				 * If we have a MeasurementFile, append parameters, otherwise don't
				 * do anything
				 */
				if (dataFile != null) {
					/*
					 * Write regular MO's
					 */
					if (!mo.equals("bulkCmConfigDataFile")) {
						/*
						 * Add the common keys to the measurement file
						 */
						dataMap.putAll(getDocMoData(mo, id));
						/*
						 * Add the DataMap to the measurement file and save the file
						 */
                        //This is modified for the TR HX49907
						HashMap<String, String> copyDataMap =new HashMap<String,String>();
		            	
		                if(isWrite)
			            {
		                	logger.log(Level.FINE, "Data Write to the Measurement file is enabled");
			            	for(int i=0;i<measurementData.size()&&i<dataMapList.size();i++)
			            	{
			                    String eleType=dataMap.get("ELEMENTTYPE");
			               		dataMapList.get(i).put("ELEMENTTYPE", eleType);
			               		measurementData.get(i).addData(dataMapList.get(i));
			            		measurementData.get(i).saveData();
			            	}
			            	measurementData.clear();
			            	dataMapList.clear();
			            	copyDataMap.clear();
			            
			            }
			            else
			            {
			            	copyDataMap.putAll(dataMap);
			            	dataMapList.add(copyDataMap);
			            	measurementData.add(dataFile);
			            	logger.log(Level.FINE, "Data Write to the Measurement file is disabled");
			            }
						
					} else {
						/*
						 * Write bulkCmConfigDataFile
						 */
						docDataMap.putAll(getDocData());
						dataFile.addData(docDataMap);
						dataFile.saveData();
						docDataMap.clear();
					}
				} else {
					logger.log(Level.WARNING, "MeasurementFile is [null] for mo " + mo + "!");
				}
				/*
				 * If we have a VectorFile, we will write
				 */
	            //vectorFile=null;
				if (vectorFile != null) {
	                /*
					 * Add the common Keys from "normal" measurementFile to
					 * vectorMeasurement, so we can get the
					 * vsDataFormatVersion,DATETIME_ID etc etc and the VECTOR
					 * counters that did have 0 or 1 values into VECTOR Measurement
					 */
					vectorFile.addData(dataMap);
					String vsDataFormatVersion = dataMap.get("vsDataFormatVersion");
					/*
					 * Iterate through VECTOR measurements
					 */
					int dcVectorIndex = 0;
					for (Entry<String, HashMap<String, String>> entry : vectorMap.entrySet()) {
						if(subVectorMap.size() > 0){
							for(Entry<String, HashMap<String, String>> vectorCounterEntry : subVectorMap.entrySet()){
								vectorFile.addData(vectorCounterEntry.getValue());
								saveVectorData(vectorFile, mo, id, vsDataFormatVersion, entry, dcVectorIndex);
								dcVectorIndex++;
							}
						}
						else{
							saveVectorData(vectorFile, mo, id, vsDataFormatVersion, entry, dcVectorIndex);
							dcVectorIndex++;
						}
					}
					if (vectorMap.size() == 0 && subVectorMap.size() > 0) {
						//vector data is present only in struct
						for(Entry<String, HashMap<String, String>> vectorCounterEntry : subVectorMap.entrySet()){
							saveVectorData(vectorFile, mo, id, vsDataFormatVersion, vectorCounterEntry, dcVectorIndex);
							dcVectorIndex++;
						}
					}
				} else {
					logger.log(Level.WARNING, "VectorFile is [null] for mo " + mo + "!");
				}

			} catch (Exception e) {
				logger.log(Level.SEVERE, "Exception while creating VectorFile for MO " + mo + "!", e);
			} finally {
				/*
				 * Once data is written, reset the DataMaps
				 */
				clearData();
			}
		}
	private Map<String, String> getDocData() {
		HashMap<String, String> docData = new HashMap<>();
		docData.put(filenameIdentifier, sourceFile.getName());
		docData.put(jvmTimezoneIdentifier, JVM_TIMEZONE);
		docData.put(dirnameIdentifier, sourceFile.getDir());
		docData.put(aomIdentifier, aom);
		docData.put(cuIdentifier, cu);
		docData.put(releaseIdentifier, release);
		docData.put(sourceIdentifier, hostname);
		docData.put(dateTimeIdentifier, datetimeId);
		docData.put(timezoneIdentifier, timeZone);
		docData.put(timelevelIdentifier, timelevel);
		docData.put(periodDurationIdentifier, periodDuration);
		docData.put(ossIdIdentifier, ossId);
		return docData;
	}
	
	private void populateSequenceIndex(MeasurementFile file, int index) {
		file.addData(sequenceIdentifier, String.valueOf(index));
	}
	
	private Map<String, String> getDocMoData(String mo, String id) {
		Map<String, String> docMoData = getDocData();
		docMoData.putAll(getMoData(mo,id));
		return docMoData;
		
	}
	
	private void saveVectorData(MeasurementFile vFile,
			String mo,
			String id,
			String vsDataFormatVersion,
			Entry<String, HashMap<String, String>> entry,
			int index) throws Exception {
				
		vFile.addData(getDocMoData(mo, id));
		populateSequenceIndex(vFile, index);
		if (vsDataFormatVersion != null) {
			vFile.addData("vsDataFormatVersion", vsDataFormatVersion);
		}
		vFile.addData(entry.getValue());
		vFile.saveData();
	}

  /**
	 * Closes all open MeasurementFiles and finishes parsing
	 * 
	 */
	public void endDocument() throws SAXException {
		logger.log(Level.FINEST, "Parser entering endDocument()....");
		stop = Calendar.getInstance().getTimeInMillis();
		for (String file : openFiles.keySet()) {
			logger.log(Level.FINEST, "Trying to close MeasurementFile " + file);
			MeasurementFile mFile = openFiles.get(file);
			try {
				mFile.close();
			} catch (Exception e) {
				logger.log(Level.SEVERE, "Unable to close MeasurementFile " + file + "!", e);
			}
		}
		logger.log(Level.INFO, "Parsing of file took " + (stop - start) / 1000 + " seconds in total.");

	}

	/**
	 * Collects the ManagedObject Id's and starts collection of attributes
	 */
	public void startElement(String namespaceURI, String localName, String qName, Attributes attrs) throws SAXException {
		/*
		 * Save the start tag for sequence handling Save the struct tag, in case
		 * the parameter is going to be StructRef
		 */
		/*
		 * Handle atribute depth Level==3, TECS-1687
		 */
		if (attributeDepth==3 && elementGrandParent==null) {
				elementGrandParent = elementParent;
		}
		
		elementParent = elementStart;
		elementStart = qName;
		
		if("configData".equals(qName))
		{
			fdnDepth=-1;
		}
		if((qName.contains("xn:SubNetwork")) || qName.contains("xn:MeContext")){
			FdnCount++;
		}
		
		if (qName.equals("xn:ManagedElement")) {
			isManagedElement = true;
		}
		/*
		 * We dont want to handle the header of the document, and we only
		 * execute this if we have id
		 */
		if ((!namespaceURI.equals("configData.xsd") || !namespaceURI.endsWith("#configData")) && attrs.getValue("id") != null) {
			/*
			 * Get the ID and the MO Class
			 */
			moId = attrs.getValue("id");
			moClass = qName.split(":")[1];
			fdnDepth++;
			/*
			 * We will initialize special cases afterwards if needed (internal
			 * mo + external mo will be handled as a same object. Standalone
			 * vsDataContainer will be initialized separately once we know the
			 * value of the tag vsDataType.
			 */
			if ((!qName.equals("xn:VsDataContainer") && !qName.equals("in:InventoryUnit"))) {
				/*
				 * If we have a new tag starting, and it's not a
				 * VsDataContainer, it can be written to the file, since it
				 * won't have a parent tag pending
				 */
				
				if (!dataMap.isEmpty()){ 
						if (elementTypesSup.isEmpty() || elementTypesSup.contains(elementType)) {
							//EDEAMAI - only write to file if the node type of this data is supported.
							//Do not writeData if there is no parent root
							if(fdn.rootMo != null){
							writeData(parentMoClass, parentMoId,false); // This is modified for the TR HX49907
							}
						} else {
							//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
							clearData();
						}
				}
				/*
				 * This is modified for the JIRA EQEV-41270
				 * Reset the rootMo and fdn once the SubNetwork or MeContext changes
				 * i.e. for the new SubNetwork/MeContext
				 */
				if( ( (qName.contains("xn:SubNetwork")) | qName.contains("xn:MeContext") ) & FdnCount == 1 ){
					logger.log(Level.FINEST, " reset the fdn and rootMO");
					fdn.reset();
					fdn.rootMo = null;
				}
				/*
				 * Handle the FDN
				 */
				// This is modified for the JIRA EQEV-38840
                fdn.handle(moClass + "=" + moId, fdnDepth);
				logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
				
				/*
				 * Store the previous MO, so we can use it to make the
				 * comparison whether the VsDataContainer following the MO
				 * container should be appended as same measurement type
				 */
				parentMoId = moId;
				parentMoClass = moClass;
			}
		} else {
			for (int i = 0; i < attrs.getLength(); i++) {
				docDataMap.put(attrs.getLocalName(i), attrs.getValue(i));
			}
		}
		/*
		 * Everytime we read an attribute, we need to mark down the depth. This
		 * is then used to check, whether the MO is a StructRef (e.g. level==
		 * 2), or just a plain attribute (level == 1)
		 */
		if (collect) {
			attributeDepth++;
		}

		/*
		 * We found attributes tag, so MO has attributes. Setting the collection
		 * flag to true
		 */
		if (qName.endsWith(":attributes")) {
			collect = true;
		}
	}
	

	
	private HashMap<String, String> getElementData() {
		final HashMap<String, String> tmpMap = new HashMap<String, String>();
		tmpMap.put("ELEMENTTYPE", elementType);
		String element=fdn.getElement();
		if( element.contains(",") ){
				tmpMap.put("ELEMENT", element.substring(0, element.indexOf(",")));
		} else {
			tmpMap.put("ELEMENT", element);
		}
		tmpMap.put("ELEMENTPARENT",fdn.getElementParent());
		return tmpMap;
		
	}

	

	/**
	 * Stops collection of attributes and writes them to file
	 */
	public void endElement(String namespaceURI, String localName, String qName) throws SAXException {
		/*
		 * Save the end tag for sequence handling
		 * Save previous element
		 */
		previousElement = elementEnd;
		elementEnd = qName;
		/*
		 * Handle the elementType tag
		 * changes for JIRA: EQEV-53994 (HX21519) 
		 */
		if ( (qName.equals(XN_MANAGEDELEMENT_TYPE)) || (qName.equals(ES_MANAGEDELEMENT_TYPE)) ) {
			elementType = characters.toString();
			if(elementType.isEmpty()||elementType==null)
			{
				elementType=OSSRC;
			}
		}
		/*
		 * Reset the element Type once we have read the whole ManagedElement XML
		 * Element
		 */
		if (qName.equals("xn:ManagedElement")) {
			writeData(parentMoClass, parentMoId,true); // This is modified for the TR HX49907
			elementType = OSSRC;
			//reset the flag.
			isManagedElement = false;
		}

		/*
		 * We dont want to handle the header of the document, and we only
		 * execute this if we collect data
		 */

		if ((!namespaceURI.equals("configData.xsd") || !namespaceURI.endsWith("#configData")) && collect) {
			/*
			 * We have an attribute ending tag here, so reduce the depth
			 */
			attributeDepth--;
			/*
			 * Handle StructRef tags
			 */
			if (attributeDepth == 2 && elementStruct == null) {
				elementStruct = elementParent;
			}
			/*
		     * Handle atribute depth Level==3, TECS-1687
		     */
		    if (attributeDepth==3 && elementGrandParent==null) {
				elementGrandParent = elementParent;
		    }
			if (attributeDepth == 2 && qName.equals(elementStruct)) {
				elementStruct = elementGrandParent;	
				elementGrandParent = null;
			}
			
			if (attributeDepth == 3 && elementStruct == null) {
				elementStruct = elementParent;
			}																																																																						   
			/*
			 * Handling the vsDataContainer and vendorUnitFamilyType, which were
			 * left out in startElement handling, since now we know exactly
			 * which MO Class the MO belongs to
			 */
			if (qName.equals("in:vendorUnitFamilyType")) {
				/*
				 * Since the Inventory XML contains multiple InventoryUnit tags,
				 * we'll replace them here with the "correct" type into the FDN,
				 * so ENIQ TechPack can distinguish them from each other easily.
				 */
				moClass = getData(characters);
				fdn.handle(moClass + "=" + moId, fdnDepth);
				logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
				dataMap.put(fdnIdentifier, fdn.getFdn());
			} else if (qName.equals("xn:vsDataType")) {
				// XTOUOOS - Save data under attribute tag
				//vsDataClass = getData(characters).replace("vsData", "");
				handleDataTypeTag();
				// XTOUOOS - Create a vector list when it reach vsDataType for its vector meas type. 
				try {
					intfName = sourceFile.getProperty("interfaceName");
					vecNameList = createVectorList(vsDataClass + "_V", intfName);
				} catch (Exception e) {
					logger.severe("Error creating VectorList : " +e);
				}
			} else if (qName.equals("xn:attributes")) {
				/*
				 * This is modified for the JIRA EQEV-41270
				 * write data to file to handle skipping of the last
				 * MO in the file 
				 */
				if (elementTypesSup.isEmpty() || elementTypesSup.contains(elementType)) {
					if (!isManagedElement) {
						writeData(parentMoClass, parentMoId,false); // This is modified for the TR HX49907
					}
				} else {
					clearData();
				}
			}
			
			/*
			 * We have reached the end of reading, write data out.
			 */
			if (qName.endsWith(":attributes")) {
				if (qName.startsWith("in:")) {
					/*
					 * For SMO Files we can always write when in:attributes tag
					 * is found.
					 */
					if (elementTypesSup.isEmpty() || elementTypesSup.contains(elementType)) {
						//EDEAMAI - Only write to file if the node type of this data is supported.
						if (!isManagedElement) {
							writeData(moClass, moId,false);// This is modified for the TR HX49907
						}
					} else {
						//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
						clearData();
					}
				}
				
				
				/*
				 * Reset the variables
				 */
				vsDataClass = null;
				moId = null;
				collect = false;
				attributeDepth = 0;
			}
			/*
			 * If we're still collecting, put the data to the map.
			 */
			if (collect) {

				/*
				 * In case of non-struct, we just put the value into the map In
				 * case the tag exists already, we know that it's a sequence
				 * then, so we take the previous value into account
				 */
				if (elementStruct == null) {
					//EDEAMAI - We are not in a struct - handle this in separate method for code clarity:
					handleNonStruct(qName);
					
				} else {
					// If the value is StructRef, then we have to append also
					// the Struct name before the parameter
					if (qName.equals(elementStruct)) {
						/*
						 * We have now reached the end of the <struct></struct>,
						 * so we reset the elementStruct flag to null, so we can
						 * continue collection of "regular" attributes from file
						 */
						elementStruct = null;
					} else {
						/*
						 * We are still inside of <struct></struct> tag, so we
						 * have to append the values to existing value. EDEAMAI - Handle struct 
						 * in seperate method for code clarity.
						 */
						
						handleStruct(qName);
					}
				}
				characters = new StringBuilder();
			}
		} else {
			/*
			 * If document tag, collect data, else decrease the FDN length
			 */
			if (namespaceURI.equals("configData.xsd") || namespaceURI.endsWith("#configData")) {
				if (qName.equals("bulkCmConfigDataFile")) {
					writeData("bulkCmConfigDataFile", "none",true);// This is modified for the TR HX49907
				}
			}
			
			fdnDepth--;
			//Reset the root_MO if the root is changed
		if((qName.contains("xn:SubNetwork")) || (qName.contains("xn:MeContext"))){
				FdnCount--;
				/*if(FdnCount < 1){
					logger.log(Level.FINEST, "Resetting the parent " );
//					fdn = new Fdn(removeRootMoR, removeVsData);
//					fdn.reset();
			}*/
			}
			}
		}
	
	/**
	 * Called by endElement when handling the "xn:vsDataType" tag
	 */
	private void handleDataTypeTag() {
		
		//Create a marker
		 
		boolean marker = false;
		
		//First, remove the vsData from the string
		vsDataClass = getData(characters).replace("vsData", "");
		
		//Check if the DataContainer following the parent is the same vsData
		 
		if (!parentMoClass.equals(vsDataClass) || !parentMoId.equals(moId)) {
			
			//If the parentMoClass is not the same as vsDataClass, or the MOs have different id, we write
			 
			marker = true;
		} 
		if (parentMoClass.equals("ManagedElement")) {
			isManagedElement = false;
		}
		//If marker was set, write data
		 
		if (marker) {
			
			 // Write the data to the file
			 
			if (!dataMap.isEmpty()){ 
				if ( elementTypesSup.isEmpty() || elementTypesSup.contains(elementType) ) {
					//EDEAMAI - Only write to file if the node type of this data is supported.
					writeData(parentMoClass, parentMoId,false);// This is modified for the TR HX49907
				} else {
					//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
					clearData();
				}
			} 
			
			 // Correct the FDN
			 
			fdn.handle(characters + "=" + moId, fdnDepth);
			
			 /* Check do we have to remove the vsData from the MO name?
			 * Set the MO into correct value, so when writing the
			 * attributes they go to correct measurement type*/
			 
			parentMoClass = vsDataClass;
			parentMoId = moId;
			logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
		}
	}
	
	private void clearData() {
		dataMap.clear();
		vectorMap.clear();
		subVectorMap.clear();
		vectorCountersIndexMap.clear();
	}
	
	private int updateAndGetVectorIndex(String key) {
		Integer vectorIndex = vectorCountersIndexMap.get(key);
		if (vectorIndex != null) {
			vectorIndex++;
		} else {
			vectorIndex =0;
		}
    	vectorCountersIndexMap.put(key, vectorIndex);
    	return vectorIndex;
	}
	
	private void populateVectorMap(int index, String key, HashMap<String, HashMap<String, String>> map) {
		HashMap<String,String> valueHolder = map.get(String.valueOf(index));
    	if(valueHolder == null){
    		valueHolder = new HashMap<String, String>();
    	}
    	valueHolder.put(key, getData(characters));        	
    	map.put(String.valueOf(index), valueHolder);
   	}

	/**
	 * Called by endElement when we're in a struct.
	 * @param qName
	 */
	private void handleStruct(String qName) {
		String key = elementStruct.split(":")[1] + structIdentifier + qName.split(":")[1];
		if (vecNameList != null && vecNameList.contains(key)) {
			populateVectorMap(updateAndGetVectorIndex(key), key, subVectorMap);
		} else {
			// XTOUOOS - Save data into DataMap
			dataMap.put(key, getData(characters));
		}
	}

	/**
	 * Called by endElement when handling attribute that are not inside a struct.
	 * @param qName
	 */
	private void handleNonStruct(String qName) {
		logger.fine("Handle Non-Struct tags");
		String key = qName.split(":")[1];
		if (vecNameList != null && vecNameList.contains(key)) {
			populateVectorMap(updateAndGetVectorIndex(key), key, vectorMap);

		} else {
			// XTOUOOS - Save data into DataMap
			//EQEV-35756:This is to handle the G2 files of the bulkcm where G1 gets mo with 1st letter caps and G2 with 1st letter small
			String test=vsDataClass+"Id";
			if(test.equalsIgnoreCase(key) && (Character.isLowerCase(key.charAt(0)))){
				key=key.substring(0, 1).toUpperCase()+ key.substring(1);
			}
			dataMap.put(key, getData(characters));
		}

	}

	/**
	 * Reads the character data between tags, e.g. <tag>character data</tag>
	 * 
	 */
	public void characters(char buf[], int offset, int len) throws SAXException {
		/*
		 * Append the corrected data to characters
		 */
		characters.append(new String(buf, offset, len).trim());
	}

	/**
	 * Initializes the Parser
	 * 
	 * @param main
	 *            - The Main Parser Object
	 * @param techPack
	 *            - The Target Techpack the parsing is done for
	 * @param setType
	 *            - The type of the Set
	 * @param setName
	 *            - The name of the Set
	 * @param workerName
	 *            - The name of the worker assigned for this parsing action
	 */
	@Override
	public void init(Main main, String techPack, String setType, String setName, String workerName) {
		this.mainParser = main;
		this.techPack = techPack;
		this.setType = setType;
		this.setName = setName;
		this.workerName = workerName;
		logger = Logger.getLogger("etl." + techPack + "." + setType + "." + setName + ".parser.XML." + workerName);
		status = 1;
	}

	/**
	 * Parses the XML file
	 * 
	 * 
	 * @param sf
	 *            - The SourceFile provided by the Main Parser
	 * @param techPack
	 *            - The Target Techpack the parsing is done for
	 * @param setType
	 *            - The type of the Set
	 * @param setName
	 *            - The name of the Set
	 */
	@Override
	public void parse(SourceFile sf, String techPack, String setType, String setName) throws Exception {
		logger.finest("Reading Interface configuration...");
		
		/*
		 * EDEAMAI - Get interface properties and set parameters in a separate method for code clarity.
		 */
		getAndSetParameters(sf);
		createOSSMappingFile(sf);
			
		/*
		 * Initialize variables
		 */
		this.techPack = techPack;
		this.setType = setType;
		this.setName = setName;
		sourceFile = sf;
		fdn = new Fdn(removeRootMoR, removeVsData,logger);
		dataMap = new HashMap<String, String>();
		docDataMap = new HashMap<String, String>();
		/*
		 * Set the type to OSSRC immediately
		 */
		vectorMap = new LinkedHashMap<>();
		subVectorMap = new LinkedHashMap<>();
		vectorCountersIndexMap = new HashMap<>();
		openFiles = new HashMap<String, MeasurementFile>();
		vectorListSet = new HashMap<String, List<String>>();
		fdn.reset();
		characters = new StringBuilder();
		moId = null;
		moClass = null;
		parentMoClass = null;
		parentMoId = null;
		fdnDepth = 0;
		attributeDepth = 0;
		collect = false;
		isStruct = false;
		elementParent = null;
		elementStart = null;
		elementStruct = null;
		elementEnd = null;
		/*
		 * Create Parser
		 */
		logger.log(Level.FINEST, "Creating SAXParser...");
		try {
			SAXParserFactory factory = SAXParserFactory.newInstance();
			factory.setNamespaceAware(true);
			factory.setValidating(true);
			SAXParser parser = factory.newSAXParser();
			logger.log(Level.FINE, "Initilizing parsing...");
			parser.parse(sf.getFileInputStream(), this);
		} catch (SAXException e) {
			
			e.printStackTrace();
			logger.log(Level.SEVERE, "Unable to parse the XML file,", e);
		} catch (IOException e) {

			e.printStackTrace();
			logger.log(Level.SEVERE, "Unable to read the XML file,", e);
		} catch (ParserConfigurationException e) {

			e.printStackTrace();
			logger.log(Level.SEVERE, "ParserConfigurationException was thrown,", e);

		}
		logger.log(Level.FINE, "Parse finished.");
	}

	/**
	 * Gets interface properties and uses then to set parameters and maps
	 * @param sf
	 */
	private void getAndSetParameters(SourceFile sf) throws Exception{
		/*
		 * Get Interface Parameters
		 */
		fdnIdentifier = sf.getProperty("BCDParser.fdnIdentifier", "FDN");
		snIdentifier = sf.getProperty("BCDParser.snIdentifier", "SN");
		moidIdentifier = sf.getProperty("BCDParser.moidIdentifier", "MOID");
		sequenceSeparator = sf.getProperty("BCDParser.sequenceSeparator", ";");
		structIdentifier = sf.getProperty("BCDParser.structIdentifier", "_");
		removeRootMoR = Boolean.parseBoolean(sf.getProperty("BCDParser.removeRootMoR", "true"));
		removeVsData = Boolean.parseBoolean(sf.getProperty("BCDParser.removeVsData", "true"));
		sequenceIdentifier = sf.getProperty("BCDParser.sequenceIdentifier","DCVECTOR_INDEX");
		aomIdentifier = sf.getProperty("BCDParser.aomIdentifier", "AOM");
		cuIdentifier = sf.getProperty("BCDParser.cuIdentifier", "CU");
		releaseIdentifier = sf.getProperty("BCDParser.releaseIdentifier","DC_RELEASE");
		dateTimeIdentifier = sf.getProperty("BCDParser.dateTimeIdentifier","DATETIME_ID");
		timezoneIdentifier = sf.getProperty("BCDParser.timezoneIdentifier","DC_TIMEZONE");
		timelevelIdentifier = sf.getProperty("BCDParser.timelevelIdentifier","TIMELEVEL");
		periodDurationIdentifier = sf.getProperty("BCDParser.periodDurationIdentifier", "PERIOD_DURATION");
		ossIdIdentifier = sf.getProperty("BCDParser.ossIdIdentifier", "OSS_ID");
		sourceIdentifier = sf.getProperty("BCDParser.sourceIdentifier","DC_SOURCE");
		dirnameIdentifier = sf.getProperty("BCDParser.sourceIdentifier","DIRNAME");
		filenameIdentifier = sf.getProperty("BCDParser.sourceIdentifier","FILENAME");
		jvmTimezoneIdentifier = sf.getProperty("BCDParser.sourceIdentifier","JVM_TIMEZONE");
		timelevel = sf.getProperty("BCDParser.timelevel", "24H");
		periodDuration = sf.getProperty("BCDParser.periodDuration", "1440");
		/*
		 * Get file transformation parameters, and read the variables in the
		 * start rather that transforming them for every single measurement type
		 */
		aomPattern = sf.getProperty("BCDParser.aomPattern", null);
		if (aomPattern != null) {
			aom = transformFileVariables("aomPattern", sf.getName(), aomPattern);
		} else {
			aom = null;
		}
		cuPattern = sf.getProperty("BCDParser.cuPattern", null);
		if (cuPattern != null) {
			cu = transformFileVariables("cuPattern", sf.getName(), cuPattern);
		} else {
			cu = null;
		}
		releasePattern = sf.getProperty("BCDParser.releasePattern", null);
		if (releasePattern != null) {
			release = transformFileVariables("releasefPattern", sf.getName(),
					releasePattern);
		} else {
			release = null;
		}
		hostnamePattern = sf.getProperty("BCDParser.hostnamePattern", null);  //Never used.
		if (hostnamePattern != null) {
			hostname = transformFileVariables("hostnamePattern", sf.getName(),
					hostnamePattern);
		} else {
			hostname = null;
		}
		datetimeIdPattern = sf.getProperty("BCDParser.datetimeIdPattern", null);
		if (datetimeIdPattern != null) {
			datetimeId = transformFileVariables("datetimeIdPattern", sf
					.getName(), datetimeIdPattern);
		} else {
			datetimeId = null;
		}
		timeZonePattern = sf.getProperty("BCDParser.timeZonePattern", null);
		if (timeZonePattern != null) {
			timeZone = transformFileVariables("timeZonePattern", sf.getName(),
					timeZonePattern);
		} else {
			timeZone = null;
		}
		ossIdPattern = sf.getProperty("BCDParser.ossIdPattern", "\\/.+?\\/.+?\\/.+?\\/(.+?)\\/.+");
		if (ossIdPattern != null) {
			ossId = transformFileVariables("ossIdPattern", sf.getDir(),
					ossIdPattern);
			// EQEV-68498 
		    if (hostname.contains(ossId) && hostname.contains(COMMA_SEPARATOR)) {
				  hostname = ossId;
			}
		} else {
			ossIdPattern = null;
		}
		
		/*
		 * EDEAMAI - Get the network element types to support.
		 */
		final StringTokenizer strToken1 = new StringTokenizer(sf.getProperty("BCDParser.elementTypesSupported", ""), ",");
		while (strToken1.hasMoreTokens()){
			String nodeType = strToken1.nextToken();
			elementTypesSup.add(nodeType); //Put the node types (if any) into an ArrayList.
			logger.info("Supporting Network Element: "+nodeType);
		}
		if(elementTypesSup.size()>0) {
			if (!elementTypesSup.contains(OSSRC)){
				//EDEAMAI - If there are any node types specified by interface then ensure OSSRC gets included. 
				elementTypesSup.add(OSSRC);
				logger.info("Supporting Network Element: OSSRC");
			}
		} else {
			logger.fine("No restrictions on Network Element type imposed by interface");
		}
		//EDEAMAI - But if there are no node types specified, then the ArrayList is left empty - which will be taken as indication 
		//that ALL node types are supported (i.e. parser will not impose any node type restriction - tech pack will be the only limiter).
		
		/*
		 * EDEAMAI - Make a default map of element types to FDN patterns.
		 */
		ConfigLookup config = new ConfigLookup();
		Map oss_mapping = config.populatingTransformation(logger);
		String enmORoss = "";
		if(oss_mapping.size()!=0)
			enmORoss = (String)oss_mapping.get(ossId);
		logger.info("OSS-ID : " + ossId + " is mapped to : " + enmORoss);
		if(ENM.equalsIgnoreCase(enmORoss))
		{
			removeRootMoR=false;
			hostname=ossId;
		}
		
	}

	/**
	 * Returns the status of parsing to the Main Parser.
	 * 
	 */
	@Override
	public int status() {
		return status;
	}

	/**
	 * Starts the BCDParser Thread and parse() action
	 */
	@Override
	public void run() {
		try {
			this.status = 2;
			SourceFile sf = null;
			parseStartTime = System.currentTimeMillis();
			while ((sf = mainParser.nextSourceFile()) != null) {
				try {
					fileCount++;
					fileSize += sf.fileSize();
					mainParser.preParse(sf);
					parse(sf, techPack, setType, setName);
					mainParser.postParse(sf);
				} catch (Exception e) {
					mainParser.errorParse(e, sf);
				} finally {
					mainParser.finallyParse(sf);
				}
			}
			totalParseTime = System.currentTimeMillis() - parseStartTime;
			if (totalParseTime != 0) {
				logger.info("Parsing Performance :: " + fileCount + " files parsed in " + totalParseTime
						+ " milliseconds, filesize is " + fileSize + " bytes and throughput : " + (fileSize / totalParseTime)
						+ " bytes/ms.");
			}
		} catch (Exception e) {
			// Exception catched at top level. No good.
			logger.log(Level.WARNING, "Worker parser failed to exception", e);
		} finally {
			this.status = 3;
		}

	}
	
	/**
	 * Populates OSS Mapping file with OSS_ALIAS to HOST_NAME mapping.
	 * 
	 * @param dir
	 * @param ossAlias
	 * @param hostName
	 */
	private void populateOssMappingFile(File mappingFile) {
		PrintWriter writer = null;
		try{
			writer = new PrintWriter(mappingFile);
			writer.println(OSS_MAPPING_HEADER);
			writer.println(ossId+COMMA_SEPARATOR+hostname);
			writer.flush();
		} catch (Exception e) {
			logger.log(Level.SEVERE, "Failed to create OSS Mapping File", e);
		} finally {
			if (writer != null) {
				writer.close();
			}
		}
	}
		
	private File getOssMappingFile (String dir) throws IOException {
		//OSSALIASMAPPING_OSSALIAS_HOSTNAME.txt 
		String mappingFileName = "OSSALIASMAPPING"+"_"+ossId+"_"+hostname+TEXT_FORMAT;
		String mappingFileDirectory = dir+"topology/";
		//Fix for EQEV-48417 (TR HW72811)
		createDirectory(mappingFileDirectory);
		return new File(mappingFileDirectory+mappingFileName);
	}
	
	private void createDirectory(String dirString) throws IOException {
		File dir = new File(dirString);
		if (!dir.exists()) {
			Files.createDirectories(dir.toPath());
		}
	}
	
	/**
	 * Parser changes for EQEV-46397
	 * Creates OSS MAPPING FILE.
	 * The file is created with the template "OSSALIASMAPPING_<OSS_ALIAS>_<HOST_NAME>.txt".
	 * The contents of the file is the mapping of OSSALIAS to HOSTNAME.
	 * 
	 * @param sf
	 */
	private void createOSSMappingFile(SourceFile sf) {
		try{
			if (hostname != null) {
				String dir = Main.resolveDirVariable(sf.getProperty("inDir"));
				dir = dir.substring(0,dir.lastIndexOf("/"));
				File ossMappingFile = getOssMappingFile(dir);
				if (!ossMappingFile.exists()) {
					ossMappingFile.createNewFile();
					populateOssMappingFile(ossMappingFile);
				}
			} else {
				logger.log(Level.SEVERE, "Not able to deduce hostName from input file");
			}
		} catch (Exception e) {
			logger.log(Level.SEVERE, "Failed to create OSS Mapping File", e);
		}
	}
	
	/**
	 * Checks if the Measurement File for the ManagedObject is already open and
	 * returns it. If Measurement File does not exist, a new file will be
	 * created and stored in cache.
	 * 
	 * @return MeasurementFile - where the parsed data will be written
	 * 
	 * @param String
	 *            mo - type of ManagedObject
	 */
	private MeasurementFile getMFile(String mo) {
		try {
			MeasurementFile msf = (MeasurementFile) openFiles.get(mo);
			if (msf == null) {
				msf = Main.createMeasurementFile(sourceFile, mo, techPack, setType, setName, this.workerName, logger);
								
				openFiles.put(mo, msf);
				
				if (vectorListSet.get(mo) == null){
				  String ifName = sourceFile.getProperty("interfaceName");
				  List<String> vectorNames = createVectorList(mo, ifName);
				  if (vectorNames != null){
				    vectorListSet.put(mo, vectorNames);
				  }
				}
			}
			return msf;
		} catch (Exception e) {
			logger.log(Level.WARNING, "Unable to create measurement file", e);
			return null;
		}
	}
	
	private List<String> createVectorList (final String tagId, final String ifName){
		List<String> vectorList = new ArrayList<String> ();
		final DataFormatCache dfc = DataFormatCache.getCache();
		final DFormat df = dfc.getFormatWithTagID(ifName, tagId);
		if (df == null) {
			return  null;
		}
    
		final List<DItem> dItemList = df.getDitems();
		for (DItem di : dItemList){
			String pi = di.getProcessInstruction();
			if (pi != null && pi.contains("VECTOR")) {
				vectorList.add(di.getDataName());
			}
		}
		return vectorList;
	}
	
	/**
	 * Returns the data of XML Elements, e.g. <tag>data</tag>.
	 * 
	 * Affecting Interface Properties:
	 * 
	 * 
	 * @return String - The formatted value of xml tags
	 * 
	 * @param StringBuilder
	 *            characters - the parsed XML characters
	 */
	private String getData(StringBuilder characters) {
		/*
		 * Get the characters data and trim it
		 */
		String data = characters.toString().trim();
		//Fix for EQEV-48452
		data = (data != null && data.length() > maxLength) ? data.substring(0,maxLength-1) : data;
		/*
		 * Remove all vsData from data, if flag is set on
		 */
		if (removeVsData) {
			data = data.replaceAll("vsData", "");
		}
		/*
		 * If the removeR is defined, search for the SubNetwork=*******_R, from
		 * the data. It has to be removed, so that the FDN matches the one in
		 * statistics
		 */
		if (removeRootMoR && data.startsWith("SubNetwork=")) {
			Pattern pattern = Pattern.compile("^SubNetwork=(.+_R),.*");
			Matcher matcher = pattern.matcher(data);
			/*
			 * Do we have FDN?
			 */
			if (matcher.matches()) {
				/*
				 * Yes we do, do we have _R in the end of RootMO
				 */
				String root = matcher.group(1);
				/*
				 * Remove _R
				 */
				String newRoot = "SubNetwork=" + root.substring(0, root.length() - 2) + ",";
				data = data.replaceAll("^SubNetwork=" + root + ",", newRoot);
			}
		}
		return data;
	}
}